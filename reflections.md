Reflections
===========

<!--
This file generated by the build script at ./Build.hs from the files in
./reflections.  If you want to edit this, edit those instead!
-->

*[2016][]* / *[2017][]* / *[2018][]* / *2019*

[2016]: https://github.com/mstksg/advent-of-code-2016/blob/master/reflections.md
[2017]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md
[2018]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md

[Available as an RSS Feed][rss]

[rss]: http://feeds.feedburner.com/jle-advent-of-code-2019

Table of Contents
-----------------

* [Day 1](#day-1)
* [Day 2](#day-2)
* [Day 3](#day-3)
* [Day 4](#day-4)
* [Day 6](#day-6)
* [Day 8](#day-8)
* [Day 10](#day-10)
* [Day 11](#day-11)

Day 1
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day01.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d01p]* / *[Code][d01g]* / *[Rendered][d01h]*

[d01p]: https://adventofcode.com/2019/day/1
[d01g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day01.hs
[d01h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day01.html


Haskell has a history of making Day 1's seem trivial :)  In this case it's a
straightforward map:

```haskell
fuel :: Int -> Int
fuel = subtract 2 . (`div` 3)

part1 :: [Int] -> Int
part1 = sum . map fuel

part2 :: [Int] -> Int
part2 = sum . map (sum . drop 1 . takeWhile (>= 0) . iterate fuel)
```

These can be parsed with `map read . lines`!

I accidentally forgot the `drop 1` the first time I submitted, so I hit the
cooldown.  Teaches me to remember to test all my answers next time :)


### Day 1 Benchmarks

```
>> Day 01a
benchmarking...
time                 1.271 μs   (1.269 μs .. 1.273 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 1.270 μs   (1.269 μs .. 1.272 μs)
std dev              3.648 ns   (1.644 ns .. 6.001 ns)

* parsing and formatting times excluded

>> Day 01b
benchmarking...
time                 20.36 μs   (20.26 μs .. 20.50 μs)
                     0.998 R²   (0.995 R² .. 1.000 R²)
mean                 20.51 μs   (20.27 μs .. 21.27 μs)
std dev              1.301 μs   (165.7 ns .. 2.695 μs)
variance introduced by outliers: 69% (severely inflated)

* parsing and formatting times excluded
```



Day 2
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day02.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d02p]* / *[Code][d02g]* / *[Rendered][d02h]*

[d02p]: https://adventofcode.com/2019/day/2
[d02g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day02.hs
[d02h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day02.html

So the bytecode/VM problems start day 2 this year, eh?

This one was also pretty straightforward.  For these types of problems, I like
to use `Data.IntMap` or `Data.Sequence` for the memory, since they both have
*O(log n)* indexing.  `Data.Sequence` is the better choice here because it's
basically `IntMap` with the indices (0, 1, 2 ...) automatically given for us :)

I usually use `Data.Sequence` instead of `Data.Vector` because it has a better
story when you want to change the length (by adding or removing elements):
`Data.Vector` is very bad, unless you have some sort of amortized abstraction.
However, in this case we don't ever change the length, so `Data.Vector` is
technically just as good here :)

So parsing:

```haskell
import           Data.List.Split (splitOn)
import           Data.Sequence (Seq(..))
import qualified Data.Sequence as Seq

type Memory = (Int, Seq Int)

parse :: String -> Memory
parse = (0,) . Seq.fromList . map read . splitOn ","
```

We write our stepping function:

```haskell
step :: Memory -> Maybe Memory
step (p, r) = do
    o <- Seq.lookup p r >>= \case
      1 -> pure (+)
      2 -> pure (*)
      _ -> empty
    [a, b, c] <- traverse (`Seq.lookup` r) [p+1 .. p+3]
    [y, z]    <- traverse (`Seq.lookup` r) [a,b]
    pure (p + 4, Seq.update c (o y z) r)
```

And away we go!

```haskell
runProg :: Memory -> Maybe Int
runProg m@(_,r) = case step m of
  Nothing -> Seq.lookup 0 r
  Just m' -> runProg m'

part1 :: String -> Maybe Int
part1 str = runProg (p, r')
  where
    (p,r) = parse str
    r'    = Seq.update 1 12 . Seq.update 2 2 $ r
```

For part 2 we can just do a brute force search

```haskell
part2 :: String -> Maybe (Int, Int)
part2 str = listToMaybe
    [ (noun, verb)
    | noun <- [0..99]
    , verb <- [0..99]
    , let r' = Seq.update 1 noun . Seq.update 2 verb $ r
    , runProg (p, r') == Just 19690720
    ]
  where
    (p, r) = parse str
```

This doesn't take too long on my machine!  But for my [actual solution][d02g],
I actually used a binary search (that I had coded up for last year). I
noticed that `noun` increases the answer by a lot, and `verb` increases it by a
little, so by doing an binary search on `noun`, then an binary search
on `verb`, you can get a good answer pretty quickly.  My part 2 time (470 μs)
is only twice as long as my part 1 time (260 μs) with the binary search. Happy
that some prep time paid off :)

```haskell
part2' :: String -> Maybe (Int, Int)
part2' str =  do
    noun <- binaryMinSearch (\i ->
        runProg (p, Seq.update 1 (i + 1) r) > Just moon
      ) 0 99
    let r' = Seq.update 1 noun r
    verb <- binaryMinSearch (\i ->
        runProg (p, Seq.update 2 (i + 1) r) > Just moon
      ) 0 99
    pure (noun, verb)
  where
    moon = 19690720
    (p, r) = parse str
```

This gets us an O(log n) search instead of an O(n^2) search, cutting down times
pretty nicely.

Just for the same of completion, I'm including my implementation of
`binaryMinSearch` here.  It's tucked away in my utilities/common
functionality file normally!

```haskell
-- | Find the lowest value where the predicate is satisfied within the
-- given bounds.
binaryMinSearch
    :: (Int -> Bool)
    -> Int                  -- ^ min
    -> Int                  -- ^ max
    -> Maybe Int
binaryMinSearch p = go
  where
    go !x !y
        | x == mid || y == mid = Just (x + 1)
        | p mid                = go x mid
        | otherwise            = go mid y
      where
        mid = ((y - x) `div` 2) + x
```


### Day 2 Benchmarks

```
>> Day 02a
benchmarking...
time                 149.6 μs   (148.9 μs .. 150.5 μs)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 149.3 μs   (149.0 μs .. 150.0 μs)
std dev              1.469 μs   (503.2 ns .. 2.490 μs)

* parsing and formatting times excluded

>> Day 02b
benchmarking...
time                 2.108 ms   (2.086 ms .. 2.132 ms)
                     0.997 R²   (0.992 R² .. 1.000 R²)
mean                 2.116 ms   (2.098 ms .. 2.181 ms)
std dev              105.1 μs   (22.51 μs .. 218.3 μs)
variance introduced by outliers: 34% (moderately inflated)

* parsing and formatting times excluded
```



Day 3
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day03.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d03p]* / *[Code][d03g]* / *[Rendered][d03h]*

[d03p]: https://adventofcode.com/2019/day/3
[d03g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day03.hs
[d03h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day03.html

As another data processing one, I feel like this might be another win for
Haskell as well :)  My part 2 leaderboard position was much higher than my
part1 position --- my suspicion is that the new twist made it difficult for
imperative coders, but the twist was naturally handled in the Haskell case.

First off, I'm going to parse the path not as a series of directions and
numbers, but rather as a list of each individual step to take.  This was
similar to my approach for [2016 Day 1][y16d1].  I'm using my favorite type for
describing points, [V2][], because it has a really useful `Num` instance to
support addition of points.

[y16d1]: https://adventofcode.com/2016/day/1
[V2]: https://hackage.haskell.org/package/linear/docs/Linear-V2.html

```haskell
import           Data.List.Split
import           Linear.V2

parsePath :: String -> [V2 Int]
parsePath = concatMap parsePoint . splitOn ","
  where
    parsePoint (d:ns) = replicate (read ns) $ case d of
      'U' -> V2   0    1
      'R' -> V2   1    0
      'D' -> V2   0  (-1)
      'L' -> V2 (-1)   0
    parsePoint _      = []
```

Now, our list of points is simply a cumulative sum, which comes from our best
friend `scanl'` (and family).  We use `scanl1` to get the running sum of all
the direction pieces, and get the set of all points.

```haskell
visited :: [V2 Int] -> Set (V2 Int)
visited = S.fromList . scanl1 (+)
```

Now Part 1 is:

```haskell
part1 :: String -> Int
part1 str = minimum (S.map mannDist (S.intersection xs ys))
  where
    [xs, ys] = map (visited . parsePath) (lines str)
    mannDist (V2 x y) = abs x + abs y
```

Once we get the intersection (the set of points that are
visited by both), we can map the `mannDist` over each intersection and find the
minimum.

Part 2 adds an "extra twist", in that now we also want to keep track of the
time it takes to reach each point.  This requires only a small tweak to
`visited`:

```haskell
visited2 :: [V2 Int] -> Map (V2 Int) Int
visited2 = M.fromListWith min        -- turn it into a map, keeping first seen
         . flip zip [1..]            -- list of (sum, time taken)
         . scanl1 (+)                -- running sum
```

We pair each item in the running sum with the time taken, and so get a map of
points seen to time taken to get to that point.  We make sure to use
`M.fromListWith min` so that we keep the *lowest* time at each point.

Part 2 is very similar, then:

```haskell
part2 :: String -> Int
part2 str = minimum (M.intersectionWith (+) xs ys)
  where
    [xs, ys] = map (visited2 . parsePath) (lines str)
```

Using `M.intersectionWith (+)` instead of `S.intersection`, because we want the
map that has the same keys in both paths, while adding together the times at
each key.

Note that we can actually solve `part1` using `visited2` instead of
`visited`...because we can "forget" the values in a `Map (V2 Int) Int` by using
`M.keysSet :: Map k a -> Set k`.


### Day 3 Benchmarks

```
>> Day 03a
benchmarking...
time                 299.0 ms   (288.7 ms .. 321.8 ms)
                     0.998 R²   (0.996 R² .. 1.000 R²)
mean                 294.8 ms   (285.8 ms .. 299.9 ms)
std dev              8.990 ms   (2.715 ms .. 12.42 ms)
variance introduced by outliers: 16% (moderately inflated)

* parsing and formatting times excluded

>> Day 03b
benchmarking...
time                 291.7 ms   (277.9 ms .. 315.9 ms)
                     0.998 R²   (0.994 R² .. 1.000 R²)
mean                 291.2 ms   (285.1 ms .. 298.0 ms)
std dev              8.427 ms   (4.731 ms .. 11.14 ms)
variance introduced by outliers: 16% (moderately inflated)

* parsing and formatting times excluded
```



Day 4
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day04.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d04p]* / *[Code][d04g]* / *[Rendered][d04h]*

[d04p]: https://adventofcode.com/2019/day/4
[d04g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day04.hs
[d04h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day04.html

I should probably appreciate these Haskell freebies while they still last :)  I
have a feeling they're not going to be this frictionless for long!

It's handy to have a function for giving us consecutive pairs of items:

```haskell
consecs :: [a] -> [(a,a)]
consecs xs = zip xs (tail xs)
```

Now for the fun part: making our filters!  For part 1, we have two filters on
the digits: first, that the digits are monotonic, and second, that at least one
pair of consecutive digits matches:

```haskell
mono :: Ord a => [a] -> Bool
mono = all (\(x,y) -> y >= x) . consecs

dups :: Eq a => [a] -> Bool
dups = any (\(x,y) -> x == y) . consecs
```

For part 2, we have two filters: the same `mono` filter, but also that we have
a group that is *exactly* length two.  For that we can use `group`, which
groups a list into chunks of equal items: `group "abbbcc" == ["a","bbb","cc"]`.
We then check if any of the chunks have a length of exactly two:

```haskell
strictDups :: Eq a => [a] -> Bool
strictDups = any ((== 2) . length) . group
```

And from here, we just run our filters on the range and count the number of
items:

```haskell
part1 :: Int -> Int -> Int
part1 mn mx = length . filter (\x -> all ($ show x) [mono, dups      ])
            $ [mn .. mx]

part2 :: Int -> Int -> Int
part2 mn mx = length . filter (\x -> all ($ show x) [mono, strictDups]) . range
            $ [mn .. mx]
```

For parsing the range, we can use `splitOn` again:

```haskell
range :: String -> (x, y)
range str = (x, y)
  where
    [x, y] =  map read (splitOn "-" str)
```

(Also, note to self next time ... if going for time, if you just have two
numbers in your input, just enter the numbers directly into the source file at
first, heh, instead of trying to parse them)



### Day 4 Benchmarks

```
>> Day 04a
benchmarking...
time                 40.54 ms   (34.93 ms .. 43.80 ms)
                     0.962 R²   (0.871 R² .. 1.000 R²)
mean                 44.23 ms   (41.85 ms .. 53.46 ms)
std dev              8.419 ms   (167.2 μs .. 15.72 ms)
variance introduced by outliers: 70% (severely inflated)

* parsing and formatting times excluded

>> Day 04b
benchmarking...
time                 42.23 ms   (41.81 ms .. 42.91 ms)
                     0.999 R²   (0.998 R² .. 1.000 R²)
mean                 42.41 ms   (42.20 ms .. 42.84 ms)
std dev              576.4 μs   (125.1 μs .. 929.9 μs)

* parsing and formatting times excluded
```



Day 6
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day06.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d06p]* / *[Code][d06g]* / *[Rendered][d06h]*

[d06p]: https://adventofcode.com/2019/day/6
[d06g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day06.hs
[d06h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day06.html

This one is pretty fun in Haskell because you get to use a trick that everyone
loves but nobody gets to use often enough --- [recursive knot tying][knot]!
Basically it's an idiomatic way to do [dynamic programming][dp] in Haskell by
taking advantage of lazy data structures ([this blog post][jelvis] is my
favorite explanation of it).

[knot]: https://wiki.haskell.org/Tying_the_Knot
[dp]: https://en.wikipedia.org/wiki/Dynamic_programming
[jelvis]: http://jelv.is/blog/Lazy-Dynamic-Programming/

The general idea is: let's say we had a map of children to parents, `Map String
String`.  To get the count of all indirect orbits, we can get a `Map String
Int`, a map of children to the number of parents and indirect parents above
them, and get the sum of those.

But how do we compute that?

Here, I'm going to show the "finale" first, and explain the way to get there:

```haskell
type Parent = String
type Child  = String

parents :: Map Child Parent

parentsCount     :: Map Child Int
parentsCount     = parents <&> \p -> case M.lookup p parentsCount of
    Nothing -> 1
    Just n  -> n + 1

parentsOfParents :: Map Child [Parent]
parentsOfParents = parents <&> \p -> case M.lookup p parentsOfParents of
    Nothing -> []
    Just ps -> p:ps
```

Fun, right?  And satisfyingly symmetrical.  That's more or less it!

So, how do we get there?

Let's call the child-parent map and the parent counts map as:

```haskell
type Parent = String
type Child  = String

parents      :: Map Child Parent
parentsCount :: Map Child Int
```


We see that the two have the same keys, so we can "map" a function over the
`parents` map to get `parentsCount`:

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = -- ?
```

So how do we `countTheParents`?  Well, we can look the parent up in
`parentsCount`, add one to the answer.  That's because if the parent has `n`
indirect parents, then the child has `n + 1` indirect parents:

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = case M.lookup p parentsCount of
    Nothing -> 1        -- count is 1
    Just n  -> n + 1    -- count is 1 + number of parents of parents
```

And that's it!


```haskell
part1 :: Int
part1 = sum parentsCount
````

The interesting thing here is that the leaves of `parentsCount` are lazily
evaluated --- so they can recursively refer to each other!

We can do `part2` in the same way, basically: we can build a list of parents of
parents of parents `"YOU"`, and then a list of parents of parents of parents of
`"SAN"`, and count the number of items that are unique to each.

```haskell
parentsOfParents :: Map Child [Parent]
parentsOfParents = fmap getPP parents

getPP :: Parent -> [Parent]
getPP p = case M.lookup p parentsOfParents of
    Nothing -> []       -- no parents
    Just pp -> p : pp   -- parent consed to parents of parents
```

Note that we actually could have defined `parentsCount` this way too:

```haskell
-- we could have done this
parentsCount :: Map Child Int
parentsCount = fmap length parentsOfParents
```

(But this is worse than the way we did it originally.  Do you see why?)


But anyway, for part 2, we will get the parents of parents of `"YOU"` and the
parents of parents of `"SAN"` and count the items that are unique to each:


```haskell
import qualified Data.Set as S

part2 :: Int
part2 = S.size onlyYou + S.size onlySan
  where
    Just you = M.lookup "YOU" parentsOfParents
    Just san = M.lookup "SAN" parentsOfParents
    onlyYou  = you S.\\ san     -- remove all items in `san` from `you`
    onlySan  = san S.\\ you     -- remove all items in `you` from `san`
```

Note that because the leaves in a `Map` are lazy, this will only actually
construct a list `[Parent]` for the keys that you look up --- parents lists for
keys you don't care about are never assembled.

The nice thing about recursive knot tying is that it gives a very concise and
readable way of saying "what you want":

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = case M.lookup p parentsCount of
    Nothing -> 1
    Just n  -> n + 1
```

This code is pretty easy to walk through, and logic of getting the parent count
(`countTheParents`) can be easily read as English: "If you get nothing when
you look up the parent in the parents count, then you only have one parent.
If you *do* get something, then it's one plus that something".

The recursive way here makes it much more readable in a "denotative" sense: you
say what it *is*, and the program/compiler figures out the rest for you.
Because of this, knot tying is often cited as one of the flashy "tech demos" of
denotative programming.  You might have seen someone write `fibs = 1 : 1 :
zipWith (+) fibs (tail fibs)` --- that's the same thing going on here.

And, with a lazy language like Haskell, it means that the leaves remain
unevaluated until we need them.  This will explode in your face in other
languages: if you evaluate all of the leaves "in order", then the first item
will depend on another unevaluated item, which might cause an error in other
languages.

It's always fun when a puzzle demonstrates so well a trick that is essential in
every Haskeller's tool belt :)


### Day 6 Benchmarks

```
>> Day 06a
benchmarking...
time                 421.3 μs   (420.6 μs .. 422.6 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 421.9 μs   (421.1 μs .. 423.3 μs)
std dev              3.687 μs   (2.282 μs .. 6.304 μs)

* parsing and formatting times excluded

>> Day 06b
benchmarking...
time                 399.6 μs   (395.2 μs .. 406.7 μs)
                     0.998 R²   (0.996 R² .. 1.000 R²)
mean                 401.3 μs   (399.7 μs .. 406.4 μs)
std dev              8.734 μs   (1.623 μs .. 18.14 μs)
variance introduced by outliers: 14% (moderately inflated)

* parsing and formatting times excluded
```



Day 8
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day08.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d08p]* / *[Code][d08g]* / *[Rendered][d08h]*

[d08p]: https://adventofcode.com/2019/day/8
[d08g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day08.hs
[d08h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day08.html

This one feels like another Haskell freebie from the early days.  I'm not
complaining, we'll take what we can get :)

We'll define a useful function that counts the number of items in a list that
is equal to a given value:

```haskell
numMatches :: Eq a => a -> [a] -> Int
numMatches x = length . filter (== x)
```

We can use the [`chunksOf`][chunksOf] function from the amazing *[split][]*
package to split our input into chunks of 150.  Then we can find the maximum of
those lines based on their zero count.  Then we encode the answer.

[chunksOf]: https://hackage.haskell.org/package/split/docs/Data-List-Split.html#v:chunksOf
[split]: https://hackage.haskell.org/package/split

```haskell
part1 :: String -> Int
part1 = encodeAnswer
      . minimumBy (comparing (numMatches '0'))
      . chunksOf 150
  where
    encodeAnswer xs = numMatches '1' xs * numMatches '2' xs
```

For part 2, we can use `transpose` turn a list of lines into a list where every
item is all of the pixel data for that pixel.  So it would turn

```
["1234"
,"1234"
,"1234"
]
```

into

```
["111"
,"222"
,"333"
,"333"
]
```

which is exactly what we need to process it.

Finding the 'pixel value' of each pixel is basically the first non-`2` pixel in
each list.  The first way that came to my mind was to use `dropWhile (==
'2')`, but `filter (/= '2')` would have worked as well.

```haskell
part2 :: String -> String
part2 = map (head . dropWhile (== '2'))
      . transpose
      . chunksOf 150
```

And that's it!  Well, almost.  Part 2 requires looking at 0/1 transparency data
and deducing our image.  For me, I wrote a function to display it nicely:

```haskell
showImage :: String -> String
showImage = unlines
          . chunksOf 25         -- number of columns
          . map (\case '0' -> ' '; _ -> '#')
```

```
#  # ###  #  # #### ###
#  # #  # #  # #    #  #
#  # ###  #  # ###  #  #
#  # #  # #  # #    ###
#  # #  # #  # #    #
 ##  ###   ##  #    #
```



### Day 8 Benchmarks

```
>> Day 08a
benchmarking...
time                 304.7 μs   (300.5 μs .. 311.0 μs)
                     0.997 R²   (0.994 R² .. 1.000 R²)
mean                 303.9 μs   (301.3 μs .. 312.2 μs)
std dev              14.42 μs   (4.890 μs .. 28.56 μs)
variance introduced by outliers: 44% (moderately inflated)

* parsing and formatting times excluded

>> Day 08b
benchmarking...
time                 259.3 μs   (257.0 μs .. 262.8 μs)
                     0.998 R²   (0.997 R² .. 1.000 R²)
mean                 261.2 μs   (258.4 μs .. 270.3 μs)
std dev              14.81 μs   (6.332 μs .. 28.23 μs)
variance introduced by outliers: 54% (severely inflated)

* parsing and formatting times excluded
```



Day 10
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day10.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d10p]* / *[Code][d10g]* / *[Rendered][d10h]*

[d10p]: https://adventofcode.com/2019/day/10
[d10g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day10.hs
[d10h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day10.html

Ah, a 2D lattice map problem -- a staple of Advent of Code, and a favorite to
many (including me!)

The first thing to do is get our map into a format we can use.  Using `V2 Int`
to represent a 2d point (because of its useful instances like `Num` and
`Applicative`), we want to get things into a `Set` of all asteroids.  This is
common enough that I have a pre-made utility function to handle this, but for
demonstration's sake we can implement it like:

```haskell
import qualified Data.Set as S

type Point = V2 Int

asteroidSet :: String -> Set Point
asteroidSet = ifoldMap (\y -> ifoldMap (\x -> crunch (V2 x y)))
            . lines
  where
    crunch p '#' = S.singleton p
    crunch _ _   = S.empty
```

Here I'm using the very handy `ifoldMap :: Monoid m => (Int -> a -> m) -> [a]`
from *[Control.Lens.Indexed][cli]*, which is a very useful function that I hope
will some day make it to *base*.  It's like `foldMap` with also the indices
available.

[cli]: https://www.stackage.org/haddock/lts-14.17/lens-4.17.1/Control-Lens-Indexed.html#v:ifoldMap

Anyway, how do we check if an asteroid is obscured?  There are probably many
good methods, but for me I found all the points in a straight line between two
asteroids, and checked if any of those items are in the asteroid field. (I did
attempt also to get the set of all unique angles, but that method ended up
being 10x slower for some reason? also using floating point equality makes me
feel queasy to my core)

```haskell
lineTo :: Point -> Point -> [Point]
lineTo p0 p1 = [ p0 + t *^ step | t <- [1 .. gcf  - 1] ]
  where
    d@(V2 dx dy) = p1 - p0
    gcf          = gcd dx dy
    step         = (`div` gcf) <$> d
```

Hopefully this shows at least is a good demonstration of why I like `V2 Int` as
`Point` so much.  We take advantages of its instances a lot, including:

*   Using the `Num` instance to compute the deltas, `V2 dx dy = p1 - p0`
*   Using the `Functor` instance to compute the step, `(`div` gcf) <$> d`
*   The handy scalar multiplication function `c *^ v`

I love `V2` :D

Anyway, the main crux of this algorithm is the list comprehension, which
computes the "steps" between the start and finish.

We can now check all the viewable points.

```haskell
viewableIn
    :: Set Point    -- ^ asteroid field
    -> Point        -- ^ vantage point
    -> Set Point    -- ^ all viewable points
viewableIn asteroids p = S.filter good (toList asteroids)
  where
    good q = p /= q
          && all (`S.notMember` asteroids) (lineTo p q)
```

Now we can do part 1:

```haskell
part1 :: Set Point -> Int
part1 asteroids = S.findMax $
    S.map (S.length . viewableIn asteroids) asteroids
```

For part 2, we are going to structure our program as an `unfoldr`.  Unfoldr
generates items while keeping some internal state.  We'll use the "currently
aimed at asteroid" and "asteroids left" as our state, and emit newly eliminated
asteroids.  Then we can simply get the 200th item in the resulting list:

```haskell
part2 :: Set Point -> Point
part2 asteroids =
    unfoldr (shootFrom station) (Nothing, asteroids) !! 199
  where
    station = maximumBy (comparing (S.size . viewableIn asteroids))
                asteroids
```

So we have `shootFrom` as our iterating function. Our "state" will be `Maybe
Point` (the asteroid our blaster is aimed at) and `Set Point`, the asteroid
field remaining.  We'll return `Nothing` when we run out of asteroids to
eliminate.

To implement `shootFrom`, it's useful to be able to sort all viewable asteroids
by the angle they make.  To do that, I made a function `angleFrom` which
computes the angle between two points, clockwise from vertical.  I use `atan2`
with some algebraic finessing to make sure north is the *minimal* amount, and
the direction moves appropriately (we flip its arguments and remember to invert
the `y` axis).

```haskell
angleTo :: Point -> Point -> Double
angleTo p0 p1 = atan2 (-fromIntegral dx) (fromIntegral dy)
  where
    V2 dx dy = p1 - p0
```

We now have all the parts to write `shootFrom`:

```haskell
shootFrom
    :: Point                                    -- ^ station
    -> (Maybe Point, Set Point)                 -- ^ current aim and remaining asteroids
    -> Maybe (Point, Maybe Point, Set Point))   -- ^ blasted asteroid, new aim, leftover field
shootFrom station (aim, asteroids) = guard (not (S.null asteroids)) $>
    case aim of
      Nothing ->
        let targ:next:_ = targetList
        in  (targ, (Just next, S.delete targ asteroids))
      Just a ->
        let targ:next:_ = dropWhile (/= a) targetList
        in  (targ, (Just next, S.delete targ asteroids))
  where
    targetList = cycle
               . sortOn (angleTo station)
               . toList
               $ viewableIn asteroids station
```

Our `targetList` is all of the remaining asteroids that are viewable from our
station, sorted by their angle from the station (0 being north, going
clockwise).  We `cycle :: [a] -> [a]` it, which loops it on itself forever, so
that the "next target" will always be the item *after* the current target.  It
turns `[a,b,c]` into `[a,b,c,a,b,c,a,b,c...]`, so if we want to ask "what
target comes after `c`?", we can see that `a` is after `c` in the cycled
version.

First, we use `guard` to return `Nothing` immediately if there are no asteroids
left.  But if there are asteroids left, we then check what we are aiming at. If
we aren't aiming at anything, just find the first item in the target list and
blast at that.  Otherwise, eat up the target list until we find the item we are
aiming at, and blast at that.  In both cases, the item after our target will be
the new item we are aiming at.

We just then need to make sure we delete our target in the new `Set Point`, to
remove it from the pool.

This one was a nice mix of math, geometry, spatial awareness, and a sense of
iterative algorithms (like `shootFrom`) -- for me, all of the best parts of an
Advent of Code challenge :)


### Day 10 Benchmarks

```
>> Day 10a
benchmarking...
time                 9.816 ms   (9.317 ms .. 10.81 ms)
                     0.895 R²   (0.759 R² .. 0.999 R²)
mean                 10.06 ms   (9.664 ms .. 11.32 ms)
std dev              1.631 ms   (483.8 μs .. 3.402 ms)
variance introduced by outliers: 76% (severely inflated)

* parsing and formatting times excluded

>> Day 10b
benchmarking...
time                 16.92 ms   (15.44 ms .. 17.83 ms)
                     0.974 R²   (0.917 R² .. 0.999 R²)
mean                 18.81 ms   (17.94 ms .. 21.21 ms)
std dev              3.739 ms   (867.5 μs .. 6.685 ms)
variance introduced by outliers: 81% (severely inflated)

* parsing and formatting times excluded
```



Day 11
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day11.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d11p]* / *[Code][d11g]* / *[Rendered][d11h]*

[d11p]: https://adventofcode.com/2019/day/11
[d11g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day11.hs
[d11h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day11.html

Okay, so I have a bit of backlog on my intcode-related posts (days 5, 7,
and 9).  But we've gotten to the point where the incode implementation isn't
the interesting part, but how we *use* it is, so maybe it's time for a fresh
start :)

This challenge affirmed my choice to use *[conduit][]* to model my Intcode VM.
(I actually use *[conduino][]*, my own lightweight alternative to *conduit*,
because it was able to handle something in Day 7 that I couldn't easily get
*conduit* to handle.  But since *conduit* is an actual industry-ready library
that is commonly used, I'm going to write this tutorial in terms of it instead)

[conduit]: https://hackage.haskell.org/package/conduit
[conduino]: https://hackage.haskell.org/package/conduino

For a "preview" of the end, my final code is more or less:

```haskell
fullBot :: Memory -> Conduit i o (State Hull) ()
fullBot m = sensor
         .| intcodeVM m
         .| painterMover
```

For those unfamiliar with *conduit*, `ConduitT i o` is a monad transformer
(like `StateT s`, or `ReaderT r`, or `WriterT w`, etc.) that offers two new
primitives:

```haskell
await :: ConduitT i o m (Maybe i)
yield :: o -> ConduitT i o m ()
```

This *should* feel very similar to similar actions from `StateT`, `ReaderT`,
and `WriterT`:

```haskell
-- similar in form to 'await'
get :: StateT  s m s
ask :: ReaderT r m r

-- similar in form to 'yield'
put  :: s -> StateT  s m ()
tell :: w -> WriterT w m ()
```

You can think of `await` like reading from an input pipe, like *stdin*: you pick off the next
item the pipe is delivering you.  You can think of `yield` like writing to an
output pipe, like *stdout*.  You can then combine conduits to create new
conduits, like `c1 .| c2` -- it feeds the output of `c1` into the input of
`c2`, etc.

So for a type like `ConduitT i o m a`, `i` is the input stream's type, `o` is
the output stream's type, `m` is the underlying monad, and `a` is the result
type that is yielded when computation finishes.


My VM machine is essentially:

```haskell
intcodeVM :: Memory -> ConduitT Int Int m Memory
```

Given some starting memory state, you return a `ConduitT Int Int m Memory`:
take `Int`s as input, output `Int`s, and when it's done, output the finished
`Memory` once we halt.

So we have our transforming pipe...what sort of input does it need, and how are
we handling the output?

The input stream is relatively simple.  Let's put together a hull state:

```haskell
type Point = V2 Int         -- V2, from linear library
data Color = Black | White

data Hull = Hull
    { hDir :: Point         -- ^ unit-length direction vector
    , hPos :: Point
    , hMap :: Map Point Color
    }

emptyHull :: Hull
emptyHull = Hull (V2 0 1) 0 M.empty
```

The underlying monad of our `Conduit` (that all components will be able to
access) will be `State Hull`.

Our input pipe is will read the current hull point and output `0` or `1` based
on black or white:

```haskell
sensor :: ConduitT i Int (State Hull) a
sensor = forever $ do
    Hull _ p m <- get
    case M.lookup p m of
      Nothing    -> yield 0     -- black
      Just Black -> yield 0     -- black
      Just White -> yield 1     -- white
```

It'll just keep on reading and yielding, forever and ever.

Our output pipe will read the input of `intcodeVM` and adjust the state
appropriately --- it's slightly trickier because we have to parse the input and
modify the state.  `await` returns a `Maybe`, so if we get two `Just`'s then we
make our changes and repeat it all over again.  Otherwise, we're done.

```haskell
painterMover :: ConduitT Int o (State Hull) ()
painterMover = do
    color <- fmap parseColor <$> await
    turn  <- fmap parseTurn  <$> await
    case (color, turn) of
      (Just c, Just t) -> do
        modify $ \(Hull d p m) ->
          let d' = t d
          in  Hull d' (p + d') (M.insert p c m)
        painterMover                -- recurse
      _                ->
        pure ()                     -- we're done!
  where
    parseColor 0 = Black
    parseColor 1 = White
    parseTurn  0 (V2 x y) = V2 (-y)   x     -- turn left
    parseTurn  1 (V2 x y) = V2   y  (-x)    -- turn right
```

And that's it!

```haskell
fullBot :: Memory -> Conduit i o (State Hull) ()
fullBot m = sensor
         .| intcodeVM m
         .| painterMover
```

We can run a full pipeline using `runConduit`:

```haskell
part1 :: Memory -> Int
part1 m = M.size m
  where
    Hull _ p m = execState (runConduit (fullBot m)) emptyHull
```

Part 2 is the same thing but we start on a painted hull:


```haskell
whiteHull :: Hull
whiteHull = Hull (V2 0 1) 0 (M.singleton 0 White)

part1 :: Memory -> Map Point Color
part1 m = m
  where
    Hull _ _ m = execState (runConduit (fullBot m)) whiteHull
```

The nice thing I like about the conduit method is that it lends itself really
well to "hooking up" the machine with input streams and output processing!  For
a machine that basically simulates stdin and stdout, it works very well, I
think!  You only need to think:

1.  How am I generating input?
2.  How am I processing output?

And your entire program will just be `generator .| intcodeVM m .| processor`.
This also worked pretty well as a mental model for Day 7 as well, because we
can easily pipe multiple independent machines: `intcodeVM m .| intcodeVM m .|
intcodeVM m`, and they will all maintain separate and independent memories as
they feed items to each other.  *conduit* handles all of the actual message
passing, and all you have to do is assemble your pipeline and let it churn
away!

Note that even if you didn't structure your intcode VM as a Conduit, it's
pretty easy to "turn it into" a `ConduitT Int Int`.  Integrating it into
conduit is nice even if you didn't intend to do it originally, using basic do
notation and combinations of `await` and `yield` and recursion.


### Day 11 Benchmarks

```
>> Day 11a
benchmarking...
time                 703.9 ms   (686.9 ms .. 719.0 ms)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 698.5 ms   (692.7 ms .. 700.6 ms)
std dev              4.108 ms   (1.441 ms .. 5.031 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded

>> Day 11b
benchmarking...
time                 49.01 ms   (48.41 ms .. 49.76 ms)
                     0.999 R²   (0.998 R² .. 1.000 R²)
mean                 48.61 ms   (48.37 ms .. 49.08 ms)
std dev              625.2 μs   (186.6 μs .. 1.027 ms)

* parsing and formatting times excluded
```

