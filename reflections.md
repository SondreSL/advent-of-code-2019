Reflections
===========

<!--
This file generated by the build script at ./Build.hs from the files in
./reflections.  If you want to edit this, edit those instead!
-->

*[2016][]* / *[2017][]* / *[2018][]* / *2019*

[2016]: https://github.com/mstksg/advent-of-code-2016/blob/master/reflections.md
[2017]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md
[2018]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md

[Available as an RSS Feed][rss]

[rss]: http://feeds.feedburner.com/jle-advent-of-code-2019

Table of Contents
-----------------

* [Day 1](#day-1)
* [Day 2](#day-2)
* [Day 3](#day-3)
* [Day 4](#day-4)
* [Day 6](#day-6)
* [Day 8](#day-8)

Day 1
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day01.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d01p]* / *[Code][d01g]* / *[Rendered][d01h]*

[d01p]: https://adventofcode.com/2019/day/1
[d01g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day01.hs
[d01h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day01.html


Haskell has a history of making Day 1's seem trivial :)  In this case it's a
straightforward map:

```haskell
fuel :: Int -> Int
fuel = subtract 2 . (`div` 3)

part1 :: [Int] -> Int
part1 = sum . map fuel

part2 :: [Int] -> Int
part2 = sum . map (sum . drop 1 . takeWhile (>= 0) . iterate fuel)
```

These can be parsed with `map read . lines`!

I accidentally forgot the `drop 1` the first time I submitted, so I hit the
cooldown.  Teaches me to remember to test all my answers next time :)


### Day 1 Benchmarks

```
>> Day 01a
benchmarking...
time                 250.6 μs   (242.6 μs .. 269.2 μs)
                     0.963 R²   (0.904 R² .. 1.000 R²)
mean                 247.8 μs   (242.5 μs .. 268.6 μs)
std dev              33.39 μs   (1.410 μs .. 70.89 μs)
variance introduced by outliers: 87% (severely inflated)

>> Day 01b
benchmarking...
time                 264.3 μs   (261.9 μs .. 268.9 μs)
                     0.999 R²   (0.997 R² .. 1.000 R²)
mean                 265.4 μs   (263.5 μs .. 270.6 μs)
std dev              9.985 μs   (3.934 μs .. 19.53 μs)
variance introduced by outliers: 34% (moderately inflated)
```



Day 2
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day02.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d02p]* / *[Code][d02g]* / *[Rendered][d02h]*

[d02p]: https://adventofcode.com/2019/day/2
[d02g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day02.hs
[d02h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day02.html

So the bytecode/VM problems start day 2 this year, eh?

This one was also pretty straightforward.  For these types of problems, I like
to use `Data.IntMap` or `Data.Sequence` for the memory, since they both have
*O(log n)* indexing.  `Data.Sequence` is the better choice here because it's
basically `IntMap` with the indices (0, 1, 2 ...) automatically given for us :)

I usually use `Data.Sequence` instead of `Data.Vector` because it has a better
story when you want to change the length (by adding or removing elements):
`Data.Vector` is very bad, unless you have some sort of amortized abstraction.
However, in this case we don't ever change the length, so `Data.Vector` is
technically just as good here :)

So parsing:

```haskell
import           Data.List.Split (splitOn)
import           Data.Sequence (Seq(..))
import qualified Data.Sequence as Seq

type Memory = (Int, Seq Int)

parse :: String -> Memory
parse = (0,) . Seq.fromList . map read . splitOn ","
```

We write our stepping function:

```haskell
step :: Memory -> Maybe Memory
step (p, r) = do
    o <- Seq.lookup p r >>= \case
      1 -> pure (+)
      2 -> pure (*)
      _ -> empty
    [a, b, c] <- traverse (`Seq.lookup` r) [p+1 .. p+3]
    [y, z]    <- traverse (`Seq.lookup` r) [a,b]
    pure (p + 4, Seq.update c (o y z) r)
```

And away we go!

```haskell
runProg :: Memory -> Maybe Int
runProg m@(_,r) = case step m of
  Nothing -> Seq.lookup 0 r
  Just m' -> runProg m'

part1 :: String -> Maybe Int
part1 str = runProg (p, r')
  where
    (p,r) = parse str
    r'    = Seq.update 1 12 . Seq.update 2 2 $ r
```

For part 2 we can just do a brute force search

```haskell
part2 :: String -> Maybe (Int, Int)
part2 str = listToMaybe
    [ (noun, verb)
    | noun <- [0..99]
    , verb <- [0..99]
    , let r' = Seq.update 1 noun . Seq.update 2 verb $ r
    , runProg (p, r') == Just 19690720
    ]
  where
    (p, r) = parse str
```

This doesn't take too long on my machine!  But for my [actual solution][d02g],
I actually used a binary search (that I had coded up for last year). I
noticed that `noun` increases the answer by a lot, and `verb` increases it by a
little, so by doing an binary search on `noun`, then an binary search
on `verb`, you can get a good answer pretty quickly.  My part 2 time (470 μs)
is only twice as long as my part 1 time (260 μs) with the binary search. Happy
that some prep time paid off :)

```haskell
part2' :: String -> Maybe (Int, Int)
part2' str =  do
    noun <- binaryMinSearch (\i ->
        runProg (p, Seq.update 1 (i + 1) r) > Just moon
      ) 0 99
    let r' = Seq.update 1 noun r
    verb <- binaryMinSearch (\i ->
        runProg (p, Seq.update 2 (i + 1) r) > Just moon
      ) 0 99
    pure (noun, verb)
  where
    moon = 19690720
    (p, r) = parse str
```

This gets us an O(log n) search instead of an O(n^2) search, cutting down times
pretty nicely.

Just for the same of completion, I'm including my implementation of
`binaryMinSearch` here.  It's tucked away in my utilities/common
functionality file normally!

```haskell
-- | Find the lowest value where the predicate is satisfied within the
-- given bounds.
binaryMinSearch
    :: (Int -> Bool)
    -> Int                  -- ^ min
    -> Int                  -- ^ max
    -> Maybe Int
binaryMinSearch p = go
  where
    go !x !y
        | x == mid || y == mid = Just (x + 1)
        | p mid                = go x mid
        | otherwise            = go mid y
      where
        mid = ((y - x) `div` 2) + x
```


### Day 2 Benchmarks

```
>> Day 02a
benchmarking...
time                 272.9 μs   (257.7 μs .. 296.2 μs)
                     0.974 R²   (0.953 R² .. 1.000 R²)
mean                 265.9 μs   (259.3 μs .. 285.0 μs)
std dev              32.76 μs   (5.613 μs .. 60.80 μs)
variance introduced by outliers: 85% (severely inflated)

>> Day 02b
benchmarking...
time                 464.2 μs   (450.5 μs .. 501.3 μs)
                     0.961 R²   (0.892 R² .. 1.000 R²)
mean                 462.9 μs   (452.3 μs .. 494.3 μs)
std dev              63.73 μs   (6.510 μs .. 122.1 μs)
variance introduced by outliers: 86% (severely inflated)
```



Day 3
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day03.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d03p]* / *[Code][d03g]* / *[Rendered][d03h]*

[d03p]: https://adventofcode.com/2019/day/3
[d03g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day03.hs
[d03h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day03.html

As another data processing one, I feel like this might be another win for
Haskell as well :)  My part 2 leaderboard position was much higher than my
part1 position --- my suspicion is that the new twist made it difficult for
imperative coders, but the twist was naturally handled in the Haskell case.

First off, I'm going to parse the path not as a series of directions and
numbers, but rather as a list of each individual step to take.  This was
similar to my approach for [2016 Day 1][y16d1].  I'm using my favorite type for
describing points, [V2][], because it has a really useful `Num` instance to
support addition of points.

[y16d1]: https://adventofcode.com/2016/day/1
[V2]: https://hackage.haskell.org/package/linear/docs/Linear-V2.html

```haskell
import           Data.List.Split
import           Linear.V2

parsePath :: String -> [V2 Int]
parsePath = concatMap parsePoint . splitOn ","
  where
    parsePoint (d:ns) = replicate (read ns) $ case d of
      'U' -> V2   0    1
      'R' -> V2   1    0
      'D' -> V2   0  (-1)
      'L' -> V2 (-1)   0
    parsePoint _      = []
```

Now, our list of points is simply a cumulative sum, which comes from our best
friend `scanl'` (and family).  We use `scanl1` to get the running sum of all
the direction pieces, and get the set of all points.

```haskell
visited :: [V2 Int] -> Set (V2 Int)
visited = S.fromList . scanl1 (+)
```

Now Part 1 is:

```haskell
part1 :: String -> Int
part1 str = minimum (S.map mannDist (S.intersection xs ys))
  where
    [xs, ys] = map (visited . parsePath) (lines str)
    mannDist (V2 x y) = abs x + abs y
```

Once we get the intersection (the set of points that are
visited by both), we can map the `mannDist` over each intersection and find the
minimum.

Part 2 adds an "extra twist", in that now we also want to keep track of the
time it takes to reach each point.  This requires only a small tweak to
`visited`:

```haskell
visited2 :: [V2 Int] -> Map (V2 Int) Int
visited2 = M.fromListWith min        -- turn it into a map, keeping first seen
         . flip zip [1..]            -- list of (sum, time taken)
         . scanl1 (+)                -- running sum
```

We pair each item in the running sum with the time taken, and so get a map of
points seen to time taken to get to that point.  We make sure to use
`M.fromListWith min` so that we keep the *lowest* time at each point.

Part 2 is very similar, then:

```haskell
part2 :: String -> Int
part2 str = minimum (M.intersectionWith (+) xs ys)
  where
    [xs, ys] = map (visited2 . parsePath) (lines str)
```

Using `M.intersectionWith (+)` instead of `S.intersection`, because we want the
map that has the same keys in both paths, while adding together the times at
each key.

Note that we can actually solve `part1` using `visited2` instead of
`visited`...because we can "forget" the values in a `Map (V2 Int) Int` by using
`M.keysSet :: Map k a -> Set k`.


### Day 3 Benchmarks

```
>> Day 03a
benchmarking...
time                 298.0 ms   (276.8 ms .. 322.1 ms)
                     0.998 R²   (0.991 R² .. 1.000 R²)
mean                 303.0 ms   (297.7 ms .. 307.2 ms)
std dev              6.642 ms   (5.044 ms .. 7.689 ms)
variance introduced by outliers: 16% (moderately inflated)

>> Day 03b
benchmarking...
time                 296.3 ms   (283.1 ms .. 314.1 ms)
                     0.999 R²   (0.998 R² .. 1.000 R²)
mean                 291.8 ms   (284.5 ms .. 295.8 ms)
std dev              6.753 ms   (2.482 ms .. 8.958 ms)
variance introduced by outliers: 16% (moderately inflated)
```



Day 4
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day04.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d04p]* / *[Code][d04g]* / *[Rendered][d04h]*

[d04p]: https://adventofcode.com/2019/day/4
[d04g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day04.hs
[d04h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day04.html

I should probably appreciate these Haskell freebies while they still last :)  I
have a feeling they're not going to be this frictionless for long!

It's handy to have a function for giving us consecutive pairs of items:

```haskell
consecs :: [a] -> [(a,a)]
consecs xs = zip xs (tail xs)
```

Now for the fun part: making our filters!  For part 1, we have two filters on
the digits: first, that the digits are monotonic, and second, that at least one
pair of consecutive digits matches:

```haskell
mono :: Ord a => [a] -> Bool
mono = all (\(x,y) -> y >= x) . consecs

dups :: Eq a => [a] -> Bool
dups = any (\(x,y) -> x == y) . consecs
```

For part 2, we have two filters: the same `mono` filter, but also that we have
a group that is *exactly* length two.  For that we can use `group`, which
groups a list into chunks of equal items: `group "abbbcc" == ["a","bbb","cc"]`.
We then check if any of the chunks have a length of exactly two:

```haskell
strictDups :: Eq a => [a] -> Bool
strictDups = any ((== 2) . length) . group
```

And from here, we just run our filters on the range and count the number of
items:

```haskell
part1 :: Int -> Int -> Int
part1 mn mx = length . filter (\x -> all ($ show x) [mono, dups      ])
            $ [mn .. mx]

part2 :: Int -> Int -> Int
part2 mn mx = length . filter (\x -> all ($ show x) [mono, strictDups]) . range
            $ [mn .. mx]
```

For parsing the range, we can use `splitOn` again:

```haskell
range :: String -> (x, y)
range str = (x, y)
  where
    [x, y] =  map read (splitOn "-" str)
```

(Also, note to self next time ... if going for time, if you just have two
numbers in your input, just enter the numbers directly into the source file at
first, heh, instead of trying to parse them)



### Day 4 Benchmarks

```
>> Day 04a
benchmarking...
time                 43.74 ms   (43.45 ms .. 44.29 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 43.58 ms   (43.49 ms .. 43.90 ms)
std dev              317.6 μs   (129.3 μs .. 563.4 μs)

>> Day 04b
benchmarking...
time                 44.23 ms   (43.64 ms .. 44.81 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 44.19 ms   (43.99 ms .. 44.76 ms)
std dev              551.8 μs   (199.9 μs .. 1.001 ms)
```



Day 6
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day06.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d06p]* / *[Code][d06g]* / *[Rendered][d06h]*

[d06p]: https://adventofcode.com/2019/day/6
[d06g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day06.hs
[d06h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day06.html

This one is pretty fun in Haskell because you get to use a trick that everyone
loves but nobody gets to use often enough --- [recursive knot tying][knot]!
Basically it's an idiomatic way to do [dynamic programming][dp] in Haskell by
taking advantage of lazy data structures ([this blog post][jelvis] is my
favorite explanation of it).

[knot]: https://wiki.haskell.org/Tying_the_Knot
[dp]: https://en.wikipedia.org/wiki/Dynamic_programming
[jelvis]: http://jelv.is/blog/Lazy-Dynamic-Programming/

The general idea is: let's say we had a map of children to parents, `Map String
String`.  To get the count of all indirect orbits, we can get a `Map String
Int`, a map of children to the number of parents and indirect parents above
them, and get the sum of those.

But how do we compute that?

Here, I'm going to show the "finale" first, and explain the way to get there:

```haskell
type Parent = String
type Child  = String

parents :: Map Child Parent

parentsCount     :: Map Child Int
parentsCount     = parents <&> \p -> case M.lookup p parentsCount of
    Nothing -> 1
    Just n  -> n + 1

parentsOfParents :: Map Child [Parent]
parentsOfParents = parents <&> \p -> case M.lookup p parentsOfParents of
    Nothing -> []
    Just ps -> p:ps
```

Fun, right?  And satisfyingly symmetrical.  That's more or less it!

So, how do we get there?

Let's call the child-parent map and the parent counts map as:

```haskell
type Parent = String
type Child  = String

parents      :: Map Child Parent
parentsCount :: Map Child Int
```


We see that the two have the same keys, so we can "map" a function over the
`parents` map to get `parentsCount`:

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = -- ?
```

So how do we `countTheParents`?  Well, we can look the parent up in
`parentsCount`, add one to the answer.  That's because if the parent has `n`
indirect parents, then the child has `n + 1` indirect parents:

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = case M.lookup p parentsCount of
    Nothing -> 1        -- count is 1
    Just n  -> n + 1    -- count is 1 + number of parents of parents
```

And that's it!


```haskell
part1 :: Int
part1 = sum parentsCount
````

The interesting thing here is that the leaves of `parentsCount` are lazily
evaluated --- so they can recursively refer to each other!

We can do `part2` in the same way, basically: we can build a list of parents of
parents of parents `"YOU"`, and then a list of parents of parents of parents of
`"SAN"`, and count the number of items that are unique to each.

```haskell
parentsOfParents :: Map Child [Parent]
parentsOfParents = fmap getPP parents

getPP :: Parent -> [Parent]
getPP p = case M.lookup p parentsOfParents of
    Nothing -> []       -- no parents
    Just pp -> p : pp   -- parent consed to parents of parents
```

Note that we actually could have defined `parentsCount` this way too:

```haskell
-- we could have done this
parentsCount :: Map Child Int
parentsCount = fmap length parentsOfParents
```

(But this is worse than the way we did it originally.  Do you see why?)


But anyway, for part 2, we will get the parents of parents of `"YOU"` and the
parents of parents of `"SAN"` and count the items that are unique to each:


```haskell
import qualified Data.Set as S

part2 :: Int
part2 = S.size onlyYou + S.size onlySan
  where
    Just you = M.lookup "YOU" parentsOfParents
    Just san = M.lookup "SAN" parentsOfParents
    onlyYou  = you S.\\ san     -- remove all items in `san` from `you`
    onlySan  = san S.\\ you     -- remove all items in `you` from `san`
```

Note that because the leaves in a `Map` are lazy, this will only actually
construct a list `[Parent]` for the keys that you look up --- parents lists for
keys you don't care about are never assembled.

The nice thing about recursive knot tying is that it gives a very concise and
readable way of saying "what you want":

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = case M.lookup p parentsCount of
    Nothing -> 1
    Just n  -> n + 1
```

This code is pretty easy to walk through, and logic of getting the parent count
(`countTheParents`) can be easily read as English: "If you get nothing when
you look up the parent in the parents count, then you only have one parent.
If you *do* get something, then it's one plus that something".

The recursive way here makes it much more readable in a "denotative" sense: you
say what it *is*, and the program/compiler figures out the rest for you.
Because of this, knot tying is often cited as one of the flashy "tech demos" of
denotative programming.  You might have seen someone write `fibs = 1 : 1 :
zipWith (+) fibs (tail fibs)` --- that's the same thing going on here.

And, with a lazy language like Haskell, it means that the leaves remain
unevaluated until we need them.  This will explode in your face in other
languages: if you evaluate all of the leaves "in order", then the first item
will depend on another unevaluated item, which might cause an error in other
languages.

It's always fun when a puzzle demonstrates so well a trick that is essential in
every Haskeller's tool belt :)


### Day 6 Benchmarks

```
>> Day 06a
benchmarking...
time                 6.336 ms   (6.110 ms .. 6.665 ms)
                     0.992 R²   (0.986 R² .. 0.999 R²)
mean                 6.175 ms   (6.114 ms .. 6.289 ms)
std dev              226.0 μs   (128.2 μs .. 371.4 μs)
variance introduced by outliers: 15% (moderately inflated)

>> Day 06b
benchmarking...
time                 4.588 ms   (3.971 ms .. 5.433 ms)
                     0.875 R²   (0.830 R² .. 0.999 R²)
mean                 4.195 ms   (4.024 ms .. 4.562 ms)
std dev              775.1 μs   (463.2 μs .. 1.166 ms)
variance introduced by outliers: 86% (severely inflated)
```



Day 8
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day08.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d08p]* / *[Code][d08g]* / *[Rendered][d08h]*

[d08p]: https://adventofcode.com/2019/day/8
[d08g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day08.hs
[d08h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day08.html

This one feels like another Haskell freebie from the early days.  I'm not
complaining, we'll take what we can get :)

We'll define a useful function that counts the number of items in a list that
is equal to a given value:

```haskell
numMatches :: Eq a => a -> [a] -> Int
numMatches x = length . filter (== x)
```

We can use the [`chunksOf`][chunksOf] function from the amazing *[split][]*
package to split our input into chunks of 150.  Then we can find the maximum of
those lines based on their zero count.  Then we encode the answer.

[chunksOf]: https://hackage.haskell.org/package/split/Data-List-Split.html#v:chunksOf
[split]: https://hackage.haskell.org/package/split

```haskell
part1 :: String -> Int
part1 = encodeAnswer
      . maximumBy (comparing (numMatchs '0'))
      . chunksOf 150
  where
    encodeAnswer xs = numMatches '1' xs * numMatches '2' xs
```

For part 2, we can use `transpose` turn a list of lines into a list where every
item is all of the pixel data for that pixel.  So it would turn

```
["1234"
,"1234"
,"1234"
]
```

into

```
["111"
,"222"
,"333"
,"333"
]
```

which is exactly what we need to process it.

Finding the 'pixel value' of each pixel is basically the first non-`2` pixel in
each list.  The first way that came to my mind was to use `dropWhile (/=
'2')`, but `filter (/= '2')` would have worked as well.

```haskell
part2 :: String -> String
part2 = map (head . dropWhile (/= '2'))
      . transpose
      . chunksOf 150
```

And that's it!  Well, almost.  Part 2 requires looking at 0/1 transparency data
and deducing our image.  For me, I wrote a function to display it nicely:

```haskell
showImage :: String -> String
showImage = unlines
          . chunksOf 25         -- number of columns
          . map (\case '0' -> ' '; _ -> '*')
```

```
*  * ***  *  * **** ***
*  * *  * *  * *    *  *
*  * ***  *  * ***  *  *
*  * *  * *  * *    ***
*  * *  * *  * *    *
 **  ***   **  *    *
```



### Day 8 Benchmarks

```
>> Day 08a
benchmarking...
time                 831.9 μs   (781.5 μs .. 927.5 μs)
                     0.958 R²   (0.920 R² .. 0.999 R²)
mean                 805.9 μs   (788.4 μs .. 844.9 μs)
std dev              89.20 μs   (51.19 μs .. 158.4 μs)
variance introduced by outliers: 78% (severely inflated)

>> Day 08b
benchmarking...
time                 1.298 ms   (1.290 ms .. 1.314 ms)
                     0.999 R²   (0.997 R² .. 1.000 R²)
mean                 1.304 ms   (1.298 ms .. 1.316 ms)
std dev              27.41 μs   (18.09 μs .. 43.71 μs)
variance introduced by outliers: 10% (moderately inflated)
```

