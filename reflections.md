Reflections
===========

<!--
This file generated by the build script at ./Build.hs from the files in
./reflections.  If you want to edit this, edit those instead!
-->

*[2016][]* / *[2017][]* / *[2018][]* / *2019*

[2016]: https://github.com/mstksg/advent-of-code-2016/blob/master/reflections.md
[2017]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md
[2018]: https://github.com/mstksg/advent-of-code-2018/blob/master/reflections.md

[Available as an RSS Feed][rss]

[rss]: http://feeds.feedburner.com/jle-advent-of-code-2019

Table of Contents
-----------------

* [Day 1](#day-1)
* [Day 2](#day-2)
* [Day 3](#day-3)
* [Day 4](#day-4)
* [Day 6](#day-6)
* [Day 8](#day-8)
* [Day 10](#day-10)

Day 1
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day01.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d01p]* / *[Code][d01g]* / *[Rendered][d01h]*

[d01p]: https://adventofcode.com/2019/day/1
[d01g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day01.hs
[d01h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day01.html


Haskell has a history of making Day 1's seem trivial :)  In this case it's a
straightforward map:

```haskell
fuel :: Int -> Int
fuel = subtract 2 . (`div` 3)

part1 :: [Int] -> Int
part1 = sum . map fuel

part2 :: [Int] -> Int
part2 = sum . map (sum . drop 1 . takeWhile (>= 0) . iterate fuel)
```

These can be parsed with `map read . lines`!

I accidentally forgot the `drop 1` the first time I submitted, so I hit the
cooldown.  Teaches me to remember to test all my answers next time :)


### Day 1 Benchmarks

```
>> Day 01a
benchmarking...
time                 250.6 μs   (242.6 μs .. 269.2 μs)
                     0.963 R²   (0.904 R² .. 1.000 R²)
mean                 247.8 μs   (242.5 μs .. 268.6 μs)
std dev              33.39 μs   (1.410 μs .. 70.89 μs)
variance introduced by outliers: 87% (severely inflated)

>> Day 01b
benchmarking...
time                 264.3 μs   (261.9 μs .. 268.9 μs)
                     0.999 R²   (0.997 R² .. 1.000 R²)
mean                 265.4 μs   (263.5 μs .. 270.6 μs)
std dev              9.985 μs   (3.934 μs .. 19.53 μs)
variance introduced by outliers: 34% (moderately inflated)
```



Day 2
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day02.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d02p]* / *[Code][d02g]* / *[Rendered][d02h]*

[d02p]: https://adventofcode.com/2019/day/2
[d02g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day02.hs
[d02h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day02.html

So the bytecode/VM problems start day 2 this year, eh?

This one was also pretty straightforward.  For these types of problems, I like
to use `Data.IntMap` or `Data.Sequence` for the memory, since they both have
*O(log n)* indexing.  `Data.Sequence` is the better choice here because it's
basically `IntMap` with the indices (0, 1, 2 ...) automatically given for us :)

I usually use `Data.Sequence` instead of `Data.Vector` because it has a better
story when you want to change the length (by adding or removing elements):
`Data.Vector` is very bad, unless you have some sort of amortized abstraction.
However, in this case we don't ever change the length, so `Data.Vector` is
technically just as good here :)

So parsing:

```haskell
import           Data.List.Split (splitOn)
import           Data.Sequence (Seq(..))
import qualified Data.Sequence as Seq

type Memory = (Int, Seq Int)

parse :: String -> Memory
parse = (0,) . Seq.fromList . map read . splitOn ","
```

We write our stepping function:

```haskell
step :: Memory -> Maybe Memory
step (p, r) = do
    o <- Seq.lookup p r >>= \case
      1 -> pure (+)
      2 -> pure (*)
      _ -> empty
    [a, b, c] <- traverse (`Seq.lookup` r) [p+1 .. p+3]
    [y, z]    <- traverse (`Seq.lookup` r) [a,b]
    pure (p + 4, Seq.update c (o y z) r)
```

And away we go!

```haskell
runProg :: Memory -> Maybe Int
runProg m@(_,r) = case step m of
  Nothing -> Seq.lookup 0 r
  Just m' -> runProg m'

part1 :: String -> Maybe Int
part1 str = runProg (p, r')
  where
    (p,r) = parse str
    r'    = Seq.update 1 12 . Seq.update 2 2 $ r
```

For part 2 we can just do a brute force search

```haskell
part2 :: String -> Maybe (Int, Int)
part2 str = listToMaybe
    [ (noun, verb)
    | noun <- [0..99]
    , verb <- [0..99]
    , let r' = Seq.update 1 noun . Seq.update 2 verb $ r
    , runProg (p, r') == Just 19690720
    ]
  where
    (p, r) = parse str
```

This doesn't take too long on my machine!  But for my [actual solution][d02g],
I actually used a binary search (that I had coded up for last year). I
noticed that `noun` increases the answer by a lot, and `verb` increases it by a
little, so by doing an binary search on `noun`, then an binary search
on `verb`, you can get a good answer pretty quickly.  My part 2 time (470 μs)
is only twice as long as my part 1 time (260 μs) with the binary search. Happy
that some prep time paid off :)

```haskell
part2' :: String -> Maybe (Int, Int)
part2' str =  do
    noun <- binaryMinSearch (\i ->
        runProg (p, Seq.update 1 (i + 1) r) > Just moon
      ) 0 99
    let r' = Seq.update 1 noun r
    verb <- binaryMinSearch (\i ->
        runProg (p, Seq.update 2 (i + 1) r) > Just moon
      ) 0 99
    pure (noun, verb)
  where
    moon = 19690720
    (p, r) = parse str
```

This gets us an O(log n) search instead of an O(n^2) search, cutting down times
pretty nicely.

Just for the same of completion, I'm including my implementation of
`binaryMinSearch` here.  It's tucked away in my utilities/common
functionality file normally!

```haskell
-- | Find the lowest value where the predicate is satisfied within the
-- given bounds.
binaryMinSearch
    :: (Int -> Bool)
    -> Int                  -- ^ min
    -> Int                  -- ^ max
    -> Maybe Int
binaryMinSearch p = go
  where
    go !x !y
        | x == mid || y == mid = Just (x + 1)
        | p mid                = go x mid
        | otherwise            = go mid y
      where
        mid = ((y - x) `div` 2) + x
```


### Day 2 Benchmarks

```
>> Day 02a
benchmarking...
time                 272.9 μs   (257.7 μs .. 296.2 μs)
                     0.974 R²   (0.953 R² .. 1.000 R²)
mean                 265.9 μs   (259.3 μs .. 285.0 μs)
std dev              32.76 μs   (5.613 μs .. 60.80 μs)
variance introduced by outliers: 85% (severely inflated)

>> Day 02b
benchmarking...
time                 464.2 μs   (450.5 μs .. 501.3 μs)
                     0.961 R²   (0.892 R² .. 1.000 R²)
mean                 462.9 μs   (452.3 μs .. 494.3 μs)
std dev              63.73 μs   (6.510 μs .. 122.1 μs)
variance introduced by outliers: 86% (severely inflated)
```



Day 3
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day03.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d03p]* / *[Code][d03g]* / *[Rendered][d03h]*

[d03p]: https://adventofcode.com/2019/day/3
[d03g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day03.hs
[d03h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day03.html

As another data processing one, I feel like this might be another win for
Haskell as well :)  My part 2 leaderboard position was much higher than my
part1 position --- my suspicion is that the new twist made it difficult for
imperative coders, but the twist was naturally handled in the Haskell case.

First off, I'm going to parse the path not as a series of directions and
numbers, but rather as a list of each individual step to take.  This was
similar to my approach for [2016 Day 1][y16d1].  I'm using my favorite type for
describing points, [V2][], because it has a really useful `Num` instance to
support addition of points.

[y16d1]: https://adventofcode.com/2016/day/1
[V2]: https://hackage.haskell.org/package/linear/docs/Linear-V2.html

```haskell
import           Data.List.Split
import           Linear.V2

parsePath :: String -> [V2 Int]
parsePath = concatMap parsePoint . splitOn ","
  where
    parsePoint (d:ns) = replicate (read ns) $ case d of
      'U' -> V2   0    1
      'R' -> V2   1    0
      'D' -> V2   0  (-1)
      'L' -> V2 (-1)   0
    parsePoint _      = []
```

Now, our list of points is simply a cumulative sum, which comes from our best
friend `scanl'` (and family).  We use `scanl1` to get the running sum of all
the direction pieces, and get the set of all points.

```haskell
visited :: [V2 Int] -> Set (V2 Int)
visited = S.fromList . scanl1 (+)
```

Now Part 1 is:

```haskell
part1 :: String -> Int
part1 str = minimum (S.map mannDist (S.intersection xs ys))
  where
    [xs, ys] = map (visited . parsePath) (lines str)
    mannDist (V2 x y) = abs x + abs y
```

Once we get the intersection (the set of points that are
visited by both), we can map the `mannDist` over each intersection and find the
minimum.

Part 2 adds an "extra twist", in that now we also want to keep track of the
time it takes to reach each point.  This requires only a small tweak to
`visited`:

```haskell
visited2 :: [V2 Int] -> Map (V2 Int) Int
visited2 = M.fromListWith min        -- turn it into a map, keeping first seen
         . flip zip [1..]            -- list of (sum, time taken)
         . scanl1 (+)                -- running sum
```

We pair each item in the running sum with the time taken, and so get a map of
points seen to time taken to get to that point.  We make sure to use
`M.fromListWith min` so that we keep the *lowest* time at each point.

Part 2 is very similar, then:

```haskell
part2 :: String -> Int
part2 str = minimum (M.intersectionWith (+) xs ys)
  where
    [xs, ys] = map (visited2 . parsePath) (lines str)
```

Using `M.intersectionWith (+)` instead of `S.intersection`, because we want the
map that has the same keys in both paths, while adding together the times at
each key.

Note that we can actually solve `part1` using `visited2` instead of
`visited`...because we can "forget" the values in a `Map (V2 Int) Int` by using
`M.keysSet :: Map k a -> Set k`.


### Day 3 Benchmarks

```
>> Day 03a
benchmarking...
time                 298.0 ms   (276.8 ms .. 322.1 ms)
                     0.998 R²   (0.991 R² .. 1.000 R²)
mean                 303.0 ms   (297.7 ms .. 307.2 ms)
std dev              6.642 ms   (5.044 ms .. 7.689 ms)
variance introduced by outliers: 16% (moderately inflated)

>> Day 03b
benchmarking...
time                 296.3 ms   (283.1 ms .. 314.1 ms)
                     0.999 R²   (0.998 R² .. 1.000 R²)
mean                 291.8 ms   (284.5 ms .. 295.8 ms)
std dev              6.753 ms   (2.482 ms .. 8.958 ms)
variance introduced by outliers: 16% (moderately inflated)
```



Day 4
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day04.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d04p]* / *[Code][d04g]* / *[Rendered][d04h]*

[d04p]: https://adventofcode.com/2019/day/4
[d04g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day04.hs
[d04h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day04.html

I should probably appreciate these Haskell freebies while they still last :)  I
have a feeling they're not going to be this frictionless for long!

It's handy to have a function for giving us consecutive pairs of items:

```haskell
consecs :: [a] -> [(a,a)]
consecs xs = zip xs (tail xs)
```

Now for the fun part: making our filters!  For part 1, we have two filters on
the digits: first, that the digits are monotonic, and second, that at least one
pair of consecutive digits matches:

```haskell
mono :: Ord a => [a] -> Bool
mono = all (\(x,y) -> y >= x) . consecs

dups :: Eq a => [a] -> Bool
dups = any (\(x,y) -> x == y) . consecs
```

For part 2, we have two filters: the same `mono` filter, but also that we have
a group that is *exactly* length two.  For that we can use `group`, which
groups a list into chunks of equal items: `group "abbbcc" == ["a","bbb","cc"]`.
We then check if any of the chunks have a length of exactly two:

```haskell
strictDups :: Eq a => [a] -> Bool
strictDups = any ((== 2) . length) . group
```

And from here, we just run our filters on the range and count the number of
items:

```haskell
part1 :: Int -> Int -> Int
part1 mn mx = length . filter (\x -> all ($ show x) [mono, dups      ])
            $ [mn .. mx]

part2 :: Int -> Int -> Int
part2 mn mx = length . filter (\x -> all ($ show x) [mono, strictDups]) . range
            $ [mn .. mx]
```

For parsing the range, we can use `splitOn` again:

```haskell
range :: String -> (x, y)
range str = (x, y)
  where
    [x, y] =  map read (splitOn "-" str)
```

(Also, note to self next time ... if going for time, if you just have two
numbers in your input, just enter the numbers directly into the source file at
first, heh, instead of trying to parse them)



### Day 4 Benchmarks

```
>> Day 04a
benchmarking...
time                 43.74 ms   (43.45 ms .. 44.29 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 43.58 ms   (43.49 ms .. 43.90 ms)
std dev              317.6 μs   (129.3 μs .. 563.4 μs)

>> Day 04b
benchmarking...
time                 44.23 ms   (43.64 ms .. 44.81 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 44.19 ms   (43.99 ms .. 44.76 ms)
std dev              551.8 μs   (199.9 μs .. 1.001 ms)
```



Day 6
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day06.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d06p]* / *[Code][d06g]* / *[Rendered][d06h]*

[d06p]: https://adventofcode.com/2019/day/6
[d06g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day06.hs
[d06h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day06.html

This one is pretty fun in Haskell because you get to use a trick that everyone
loves but nobody gets to use often enough --- [recursive knot tying][knot]!
Basically it's an idiomatic way to do [dynamic programming][dp] in Haskell by
taking advantage of lazy data structures ([this blog post][jelvis] is my
favorite explanation of it).

[knot]: https://wiki.haskell.org/Tying_the_Knot
[dp]: https://en.wikipedia.org/wiki/Dynamic_programming
[jelvis]: http://jelv.is/blog/Lazy-Dynamic-Programming/

The general idea is: let's say we had a map of children to parents, `Map String
String`.  To get the count of all indirect orbits, we can get a `Map String
Int`, a map of children to the number of parents and indirect parents above
them, and get the sum of those.

But how do we compute that?

Here, I'm going to show the "finale" first, and explain the way to get there:

```haskell
type Parent = String
type Child  = String

parents :: Map Child Parent

parentsCount     :: Map Child Int
parentsCount     = parents <&> \p -> case M.lookup p parentsCount of
    Nothing -> 1
    Just n  -> n + 1

parentsOfParents :: Map Child [Parent]
parentsOfParents = parents <&> \p -> case M.lookup p parentsOfParents of
    Nothing -> []
    Just ps -> p:ps
```

Fun, right?  And satisfyingly symmetrical.  That's more or less it!

So, how do we get there?

Let's call the child-parent map and the parent counts map as:

```haskell
type Parent = String
type Child  = String

parents      :: Map Child Parent
parentsCount :: Map Child Int
```


We see that the two have the same keys, so we can "map" a function over the
`parents` map to get `parentsCount`:

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = -- ?
```

So how do we `countTheParents`?  Well, we can look the parent up in
`parentsCount`, add one to the answer.  That's because if the parent has `n`
indirect parents, then the child has `n + 1` indirect parents:

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = case M.lookup p parentsCount of
    Nothing -> 1        -- count is 1
    Just n  -> n + 1    -- count is 1 + number of parents of parents
```

And that's it!


```haskell
part1 :: Int
part1 = sum parentsCount
````

The interesting thing here is that the leaves of `parentsCount` are lazily
evaluated --- so they can recursively refer to each other!

We can do `part2` in the same way, basically: we can build a list of parents of
parents of parents `"YOU"`, and then a list of parents of parents of parents of
`"SAN"`, and count the number of items that are unique to each.

```haskell
parentsOfParents :: Map Child [Parent]
parentsOfParents = fmap getPP parents

getPP :: Parent -> [Parent]
getPP p = case M.lookup p parentsOfParents of
    Nothing -> []       -- no parents
    Just pp -> p : pp   -- parent consed to parents of parents
```

Note that we actually could have defined `parentsCount` this way too:

```haskell
-- we could have done this
parentsCount :: Map Child Int
parentsCount = fmap length parentsOfParents
```

(But this is worse than the way we did it originally.  Do you see why?)


But anyway, for part 2, we will get the parents of parents of `"YOU"` and the
parents of parents of `"SAN"` and count the items that are unique to each:


```haskell
import qualified Data.Set as S

part2 :: Int
part2 = S.size onlyYou + S.size onlySan
  where
    Just you = M.lookup "YOU" parentsOfParents
    Just san = M.lookup "SAN" parentsOfParents
    onlyYou  = you S.\\ san     -- remove all items in `san` from `you`
    onlySan  = san S.\\ you     -- remove all items in `you` from `san`
```

Note that because the leaves in a `Map` are lazy, this will only actually
construct a list `[Parent]` for the keys that you look up --- parents lists for
keys you don't care about are never assembled.

The nice thing about recursive knot tying is that it gives a very concise and
readable way of saying "what you want":

```haskell
parentsCount :: Map Child Int
parentsCount = fmap countTheParents parents

countTheParents :: Parent -> Int
countTheParents p = case M.lookup p parentsCount of
    Nothing -> 1
    Just n  -> n + 1
```

This code is pretty easy to walk through, and logic of getting the parent count
(`countTheParents`) can be easily read as English: "If you get nothing when
you look up the parent in the parents count, then you only have one parent.
If you *do* get something, then it's one plus that something".

The recursive way here makes it much more readable in a "denotative" sense: you
say what it *is*, and the program/compiler figures out the rest for you.
Because of this, knot tying is often cited as one of the flashy "tech demos" of
denotative programming.  You might have seen someone write `fibs = 1 : 1 :
zipWith (+) fibs (tail fibs)` --- that's the same thing going on here.

And, with a lazy language like Haskell, it means that the leaves remain
unevaluated until we need them.  This will explode in your face in other
languages: if you evaluate all of the leaves "in order", then the first item
will depend on another unevaluated item, which might cause an error in other
languages.

It's always fun when a puzzle demonstrates so well a trick that is essential in
every Haskeller's tool belt :)


### Day 6 Benchmarks

```
>> Day 06a
benchmarking...
time                 6.336 ms   (6.110 ms .. 6.665 ms)
                     0.992 R²   (0.986 R² .. 0.999 R²)
mean                 6.175 ms   (6.114 ms .. 6.289 ms)
std dev              226.0 μs   (128.2 μs .. 371.4 μs)
variance introduced by outliers: 15% (moderately inflated)

>> Day 06b
benchmarking...
time                 4.588 ms   (3.971 ms .. 5.433 ms)
                     0.875 R²   (0.830 R² .. 0.999 R²)
mean                 4.195 ms   (4.024 ms .. 4.562 ms)
std dev              775.1 μs   (463.2 μs .. 1.166 ms)
variance introduced by outliers: 86% (severely inflated)
```



Day 8
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day08.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d08p]* / *[Code][d08g]* / *[Rendered][d08h]*

[d08p]: https://adventofcode.com/2019/day/8
[d08g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day08.hs
[d08h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day08.html

This one feels like another Haskell freebie from the early days.  I'm not
complaining, we'll take what we can get :)

We'll define a useful function that counts the number of items in a list that
is equal to a given value:

```haskell
numMatches :: Eq a => a -> [a] -> Int
numMatches x = length . filter (== x)
```

We can use the [`chunksOf`][chunksOf] function from the amazing *[split][]*
package to split our input into chunks of 150.  Then we can find the maximum of
those lines based on their zero count.  Then we encode the answer.

[chunksOf]: https://hackage.haskell.org/package/split/docs/Data-List-Split.html#v:chunksOf
[split]: https://hackage.haskell.org/package/split

```haskell
part1 :: String -> Int
part1 = encodeAnswer
      . minimumBy (comparing (numMatches '0'))
      . chunksOf 150
  where
    encodeAnswer xs = numMatches '1' xs * numMatches '2' xs
```

For part 2, we can use `transpose` turn a list of lines into a list where every
item is all of the pixel data for that pixel.  So it would turn

```
["1234"
,"1234"
,"1234"
]
```

into

```
["111"
,"222"
,"333"
,"333"
]
```

which is exactly what we need to process it.

Finding the 'pixel value' of each pixel is basically the first non-`2` pixel in
each list.  The first way that came to my mind was to use `dropWhile (==
'2')`, but `filter (/= '2')` would have worked as well.

```haskell
part2 :: String -> String
part2 = map (head . dropWhile (== '2'))
      . transpose
      . chunksOf 150
```

And that's it!  Well, almost.  Part 2 requires looking at 0/1 transparency data
and deducing our image.  For me, I wrote a function to display it nicely:

```haskell
showImage :: String -> String
showImage = unlines
          . chunksOf 25         -- number of columns
          . map (\case '0' -> ' '; _ -> '#')
```

```
#  # ###  #  # #### ###
#  # #  # #  # #    #  #
#  # ###  #  # ###  #  #
#  # #  # #  # #    ###
#  # #  # #  # #    #
 ##  ###   ##  #    #
```



### Day 8 Benchmarks

```
>> Day 08a
benchmarking...
time                 824.3 μs   (806.0 μs .. 865.9 μs)
                     0.958 R²   (0.879 R² .. 0.999 R²)
mean                 829.7 μs   (807.2 μs .. 912.3 μs)
std dev              134.3 μs   (15.92 μs .. 283.1 μs)
variance introduced by outliers: 89% (severely inflated)

>> Day 08b
benchmarking...
time                 1.467 ms   (1.357 ms .. 1.706 ms)
                     0.891 R²   (0.788 R² .. 1.000 R²)
mean                 1.399 ms   (1.360 ms .. 1.553 ms)
std dev              243.4 μs   (15.14 μs .. 518.2 μs)
variance introduced by outliers: 88% (severely inflated)
```



Day 10
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day10.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d10p]* / *[Code][d10g]* / *[Rendered][d10h]*

[d10p]: https://adventofcode.com/2019/day/10
[d10g]: https://github.com/mstksg/advent-of-code-2019/blob/master/src/AOC/Challenge/Day10.hs
[d10h]: https://mstksg.github.io/advent-of-code-2019/src/AOC.Challenge.Day10.html

Ah, a 2D lattice map problem -- a staple of Advent of Code, and a favorite to
many (including me!)

The first thing to do is get our map into a format we can use.  Using `V2 Int`
to represent a 2d point (because of its useful instances like `Num` and
`Applicative`), we want to get things into a `Set` of all asteroids.  This is
common enough that I have a pre-made utility function to handle this, but for
demonstration's sake we can implement it like:

```haskell
import qualified Data.Set as S

type Point = V2 Int

asteroidSet :: String -> Set Point
asteroidSet = ifoldMap (\y -> ifoldMap (\x -> crunch (V2 x y)))
            . lines
  where
    crunch p '#' = S.singleton p
    crunch _ _   = S.empty
```

Here I'm using the very handy `ifoldMap :: Monoid m => (Int -> a -> m) -> [a]`
from *[Control.Lens.Indexed][cli]*, which is a very useful function that I hope
will some day make it to *base*.  It's like `foldMap` with also the indices
available.

[cli]: https://www.stackage.org/haddock/lts-14.17/lens-4.17.1/Control-Lens-Indexed.html#v:ifoldMap

Anyway, how do we check if an asteroid is obscured?  There are probably many
good methods, but for me I found all the points in a straight line between two
asteroids, and checked if any of those items are in the asteroid field. (I did
attempt also to get the set of all unique angles, but that method ended up
being 10x slower for some reason?)

```haskell
lineTo :: Point -> Point -> [Point]
lineTo p0 p1
    | dy == 0   = [ V2 x    minY   | x <- [minX + 1 .. maxX - 1] ]
    | otherwise = [ p0 + t *^ step | t <- [1        .. gcf  - 1] ]
  where
    V2 minX minY = min <$> p0 <*> p1
    V2 maxX _    = max <$> p0 <*> p1
    d@(V2 dx dy) = p1 - p0
    gcf          = gcd dx dy
    step         = (`div` gcf) <$> d
```

Whoo, that one is kind of a doozy, isn't it?  Well, hopefully this shows at least
is a good demonstration of why I like `V2 Int` as `Point` so much.  We take
advantages of its instances a lot, including:

*   Using `min <$> p0 <*> p1` to find the component-wise minimum of two points
    to get `V2 minX minY`
*   Using the `Num` instance to compute the deltas, `V2 dx dy = p1 - p0`
*   Using the `Functor` instance to compute the step, `(`div` gcf) <$> d`
*   The handy scalar multiplication function `c *^ v`

I love `V2` :D

Anyway, the main crux of this algorithm is the final branch, which computes
the "steps" between the start and finish.  The first branch is a special-case
situation where `dy == 0` (a horizontal line) and `gcd dx dy` is undefined.

Anyway, we can now check all the viewable points.

```haskell
viewableIn
    :: Set Point    -- ^ asteroid field
    -> Point        -- ^ vantage point
    -> Set Point    -- ^ all viewable points
viewableIn asteroids p = S.filter good (toList asteroids)
  where
    good q = p /= q
          && all (`S.notMember` asteroids) (lineTo p q)
```

Now we can do part 1:

```haskell
part1 :: Set Point -> Int
part1 asteroids = S.findMax $
    S.map (S.length . viewableIn asteroids) asteroids
```

For part 2, we are going to structure our program as an `unfoldr`.  Unfoldr
generates items while keeping some internal state.  We'll use the "currently
aimed at asteroid" and "asteroids left" as our state, and emit newly eliminated
asteroids.  Then we can simply get the 200th item in the resulting list:

```haskell
part2 :: Set Point -> Point
part2 asteroids =
    unfoldr (shootFrom station) (Nothing, asteroids) !! 199
  where
    station = maximumBy (comparing (S.size . viewableIn asteroids))
                asteroids
```

So we have `shootFrom` as our iterating function. Our "state" will be `Maybe
Point` (the asteroid our blaster is aimed at) and `Set Point`, the asteroid
field remaining.  We'll return `Nothing` when we run out of asteroids to
eliminate.

To implement `shootFrom`, it's useful to be able to sort all viewable asteroids
by the angle they make.  To do that, I made a function `angleFrom` which
computes the angle between two points, clockwise from vertical.  I use `atan2`
with some algebraic finessing to make sure north is the *minimal* amount, and
the direction moves appropriately (we flip its arguments and remember to invert
the `y` axis).

```haskell
angleTo :: Point -> Point -> Double
angleTo p0 p1 = atan2 (-fromIntegral dx) (fromIntegral dy)
  where
    V2 dx dy = p1 - p0
```

We now have all the parts to write `shootFrom`:

```haskell
shootFrom
    :: Point                            -- ^ station
    -> (Maybe Point, Set Point)         -- ^ current aim and remaining asteroids
    -> Maybe (Maybe Point, Set Point)   -- ^ new aim, leftover field
shootFrom station (aim, asteroids) = guard (not (S.null asteroids)) $>
    case aim of
      Nothing ->
        let targ:next:_ = targetList
        in  (Just targ, (next, S.delete targ asteroids))
      Just a ->
        let targ:next:_ = dropWhile (/= a) targetList
        in  (Just targ, (next, S.delete targ asteroids))
  where
    targetList = cycle
               . sortOn (angleTo station)
               . toList
               $ viewableIn asteroids station
```

Our `targetList` is all of the remaining asteroids that are viewable from our
station, sorted by their angle from the station (0 being north, going
clockwise).  We `cycle :: [a] -> [a]` it, which loops it on itself forever, so
that the "next target" will always be the item *after* the current target.  It
turns `[a,b,c]` into `[a,b,c,a,b,c,a,b,c...]`, so if we want to ask "what
target comes after `c`?", we can see that `a` is after `c` in the cycled
version.

First, we use `guard` to return `Nothing` immediately if there are no asteroids
left.  But if there are asteroids left, we then check what we are aiming at. If
we aren't aiming at anything, just find the first item in the target list and
blast at that.  Otherwise, eat up the target list until we find the item we are
aiming at, and blast at that.  In both cases, the item after our target will be
the new item we are aiming at.

We just then need to make sure we delete our target in the new `Set Point`, to
remove it from the pool.

This one was a nice mix of math, geometry, spatial awareness, and a sense of
iterative algorithms (like `shootFrom`) -- for me, all of the best parts of an
Advent of Code challenge :)


### Day 10 Benchmarks

```
>> Day 10a
benchmarking...
time                 10.25 ms   (9.895 ms .. 10.88 ms)
                     0.964 R²   (0.915 R² .. 1.000 R²)
mean                 10.22 ms   (9.988 ms .. 10.77 ms)
std dev              954.9 μs   (477.5 μs .. 1.725 ms)
variance introduced by outliers: 52% (severely inflated)

>> Day 10b
benchmarking...
time                 18.10 ms   (17.72 ms .. 18.50 ms)
                     0.998 R²   (0.996 R² .. 0.999 R²)
mean                 18.06 ms   (17.92 ms .. 18.30 ms)
std dev              466.9 μs   (329.4 μs .. 709.0 μs)
```

